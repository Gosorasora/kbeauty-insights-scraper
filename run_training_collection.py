#!/usr/bin/env python3
"""
YouTube AI í•™ìŠµìš© ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
========================================

ì¼ë³„ ë°°ì¹˜ë¡œ YouTube í•™ìŠµ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ CSV íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ìˆ˜ì§‘
    python run_training_collection.py
    
    # íŠ¹ì • ë‚ ì§œë¡œ ìˆ˜ì§‘
    python run_training_collection.py --date 2026-01-01
    
    # ë‚ ì§œ ë²”ìœ„ë¡œ ë°°ì¹˜ ìˆ˜ì§‘
    python run_training_collection.py --start-date 2025-12-28 --end-date 2025-12-31

í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
    export YOUTUBE_API_KEYS="your_api_key1,your_api_key2"
"""

import asyncio
import argparse
import sys
from datetime import datetime, timedelta
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from src.viral_detection_system import YouTubeTrainingSystem, load_config_from_env
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="YouTube AI í•™ìŠµìš© ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  %(prog)s                                    # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ìˆ˜ì§‘
  %(prog)s --date 2026-01-01                  # íŠ¹ì • ë‚ ì§œë¡œ ìˆ˜ì§‘
  %(prog)s --start-date 2025-12-28 --end-date 2025-12-31  # ë°°ì¹˜ ìˆ˜ì§‘
        """
    )
    
    parser.add_argument(
        '--date',
        type=str,
        help='ìˆ˜ì§‘í•  ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)'
    )
    
    parser.add_argument(
        '--start-date',
        type=str,
        help='ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)'
    )
    
    parser.add_argument(
        '--end-date',
        type=str,
        help='ë°°ì¹˜ ìˆ˜ì§‘ ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)'
    )
    
    parser.add_argument(
        '--output-dir',
        type=str,
        default='results',
        help='ê²°ê³¼ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: results)'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )
    
    return parser.parse_args()


def validate_date(date_str: str) -> bool:
    """ë‚ ì§œ í˜•ì‹ ê²€ì¦"""
    try:
        datetime.strptime(date_str, '%Y-%m-%d')
        return True
    except ValueError:
        return False


def generate_date_range(start_date: str, end_date: str) -> list:
    """ë‚ ì§œ ë²”ìœ„ ìƒì„±"""
    try:
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        if start > end:
            raise ValueError("ì‹œì‘ ë‚ ì§œê°€ ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤")
        
        date_list = []
        current = start
        while current <= end:
            date_list.append(current.strftime('%Y-%m-%d'))
            current += timedelta(days=1)
        
        return date_list
        
    except ValueError as e:
        logger.error(f"ë‚ ì§œ ë²”ìœ„ ìƒì„± ì‹¤íŒ¨: {e}")
        return []


async def run_single_collection(system: YouTubeTrainingSystem, target_date: str):
    """ë‹¨ì¼ ë‚ ì§œ ë°ì´í„° ìˆ˜ì§‘"""
    logger.info(f"ğŸš€ ë‹¨ì¼ ìˆ˜ì§‘ ì‹œì‘: {target_date}")
    
    stats = await system.run_daily_collection(target_date)
    
    if stats.csv_file_path:
        logger.info(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {stats.csv_file_path}")
        logger.info(f"   - ì²˜ë¦¬ëœ ì˜ìƒ: {stats.total_videos_processed}ê°œ")
        logger.info(f"   - íŠ¸ë Œë”© ì˜ìƒ: {stats.trending_videos_count}ê°œ")
        logger.info(f"   - íŒŒì¼ í¬ê¸°: {stats.file_size_bytes:,} bytes")
        return True
    else:
        logger.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        return False


async def run_batch_collection(system: YouTubeTrainingSystem, date_range: list):
    """ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘"""
    logger.info(f"ğŸš€ ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘: {len(date_range)}ê°œ ë‚ ì§œ")
    logger.info(f"   - ë‚ ì§œ ë²”ìœ„: {date_range[0]} ~ {date_range[-1]}")
    
    all_stats = await system.run_batch_collection(date_range)
    
    if all_stats:
        successful_collections = [stats for stats in all_stats if stats.csv_file_path]
        total_videos = sum(stats.total_videos_processed for stats in successful_collections)
        total_trending = sum(stats.trending_videos_count for stats in successful_collections)
        
        logger.info(f"âœ… ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ")
        logger.info(f"   - ì„±ê³µí•œ ìˆ˜ì§‘: {len(successful_collections)}/{len(date_range)}")
        logger.info(f"   - ì´ ì˜ìƒ ìˆ˜: {total_videos:,}ê°œ")
        logger.info(f"   - ì´ íŠ¸ë Œë”©: {total_trending:,}ê°œ")
        
        # ìƒì„±ëœ íŒŒì¼ ëª©ë¡
        logger.info("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
        for stats in successful_collections:
            if stats.csv_file_path:
                logger.info(f"   - {stats.csv_file_path}")
        
        return len(successful_collections) > 0
    else:
        logger.error("âŒ ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤íŒ¨")
        return False


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    args = parse_arguments()
    
    # ë¡œê¹… ë ˆë²¨ ì„¤ì •
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    logger.info("ğŸ¯ YouTube AI í•™ìŠµìš© ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ")
    logger.info("=" * 50)
    
    try:
        # ì„¤ì • ë¡œë“œ
        config = load_config_from_env()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if args.output_dir:
            config.output_directory = args.output_dir
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        system = YouTubeTrainingSystem(config)
        
        logger.info(f"ğŸ“‹ ì‹œìŠ¤í…œ ì„¤ì •:")
        logger.info(f"   - API í‚¤ ê°œìˆ˜: {len(config.youtube_api_keys)}")
        logger.info(f"   - ì¶œë ¥ ë””ë ‰í† ë¦¬: {config.output_directory}")
        logger.info(f"   - ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
        
        # ì‹¤í–‰ ëª¨ë“œ ê²°ì •
        if args.start_date and args.end_date:
            # ë°°ì¹˜ ìˆ˜ì§‘ ëª¨ë“œ
            if not validate_date(args.start_date) or not validate_date(args.end_date):
                logger.error("âŒ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                return False
            
            date_range = generate_date_range(args.start_date, args.end_date)
            if not date_range:
                return False
            
            if len(date_range) > 7:
                confirm = input(f"âš ï¸ {len(date_range)}ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                if confirm.lower() != 'y':
                    logger.info("ìˆ˜ì§‘ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    return False
            
            success = await run_batch_collection(system, date_range)
            
        else:
            # ë‹¨ì¼ ìˆ˜ì§‘ ëª¨ë“œ
            target_date = args.date
            
            if target_date:
                if not validate_date(target_date):
                    logger.error("âŒ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                    return False
            else:
                target_date = datetime.now().strftime('%Y-%m-%d')
                logger.info(f"ğŸ“… ë‚ ì§œê°€ ì§€ì •ë˜ì§€ ì•Šì•„ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤: {target_date}")
            
            success = await run_single_collection(system, target_date)
        
        if success:
            logger.info("ğŸ‰ ë°ì´í„° ìˆ˜ì§‘ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            logger.error("âŒ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
            
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìê°€ ìˆ˜ì§‘ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    return True


if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)