"""
YouTube Training Data Collection System
======================================

AI ëª¨ë¸ í•™ìŠµìš© YouTube ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
ì¼ë³„ ë°°ì¹˜ë¡œ ì‹¤í–‰ë˜ì–´ í•™ìŠµ ë°ì´í„°ì…‹(CSV)ì„ ìƒì„±

ì£¼ìš” ê¸°ëŠ¥:
- YouTube API ê¸°ë°˜ ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (ê±°ì‹œ íŠ¸ë Œë“œ, í‚¤ì›Œë“œ ë°œêµ´, ì±„ë„ ì„±ê³¼)
- í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (View Velocity, VPV, Engagement Rate)
- ë°ì´í„° ì •ì œ ë° í’ˆì§ˆ ê´€ë¦¬
- CSV ë°ì´í„°ì…‹ ìƒì„± (UTF-8-SIG, SRS ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜)
- ì¼ë³„ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ë§ ë° í†µê³„ ë¦¬í¬íŒ…

ì‚¬ìš©ë²•:
    from src.viral_detection_system import YouTubeTrainingSystem
    
    config = load_config_from_env()
    system = YouTubeTrainingSystem(config)
    stats = await system.run_daily_collection()
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import json
import os

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from src.collectors.youtube_training_data_collector import YouTubeTrainingDataCollector, VideoTrainingData

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('viral_detection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class TrainingSystemConfig:
    """í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì„¤ì •"""
    # API í‚¤
    youtube_api_keys: List[str]
    
    # ìˆ˜ì§‘ ì„¤ì •
    collection_schedule: str = "daily"  # daily, hourly
    batch_size: int = 100
    max_concurrent_tasks: int = 5
    
    # ë°ì´í„° ì €ì¥ ì„¤ì •
    output_directory: str = "results"
    csv_encoding: str = "utf-8-sig"
    
    # í’ˆì§ˆ ê´€ë¦¬ ì„¤ì •
    min_view_count: int = 1000  # ìµœì†Œ ì¡°íšŒìˆ˜ í•„í„°
    enable_data_validation: bool = True


@dataclass
class CollectionStats:
    """ìˆ˜ì§‘ í†µê³„"""
    start_time: str
    end_time: str
    total_videos_collected: int
    total_videos_processed: int
    trending_videos_count: int
    csv_file_path: str
    file_size_bytes: int
    api_quota_used: int
    error_count: int


class YouTubeTrainingSystem:
    """YouTube AI í•™ìŠµìš© ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: TrainingSystemConfig):
        """
        í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            config: ì‹œìŠ¤í…œ ì„¤ì •
        """
        self.config = config
        self.is_running = False
        self.stats = CollectionStats(
            start_time="",
            end_time="",
            total_videos_collected=0,
            total_videos_processed=0,
            trending_videos_count=0,
            csv_file_path="",
            file_size_bytes=0,
            api_quota_used=0,
            error_count=0
        )
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.data_collector = None
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.config.output_directory, exist_ok=True)
    
    async def run_daily_collection(self, target_date: Optional[str] = None) -> CollectionStats:
        """
        ì¼ë³„ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        
        Args:
            target_date: ìˆ˜ì§‘ ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD), Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ
            
        Returns:
            ìˆ˜ì§‘ í†µê³„
        """
        if target_date is None:
            target_date = datetime.now().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸš€ YouTube í•™ìŠµ ë°ì´í„° ì¼ë³„ ìˆ˜ì§‘ ì‹œì‘ (ë‚ ì§œ: {target_date})")
        
        start_time = datetime.now()
        self.stats.start_time = start_time.isoformat()
        self.is_running = True
        
        try:
            # ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
            await self._initialize_collector()
            
            # í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ë° CSV ìƒì„±
            csv_path = await self.data_collector.collect_daily_dataset(target_date)
            
            if csv_path:
                # í†µê³„ ì—…ë°ì´íŠ¸
                await self._update_collection_stats(csv_path)
                
                logger.info("âœ… ì¼ë³„ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                logger.info(f"   - CSV íŒŒì¼: {self.stats.csv_file_path}")
                logger.info(f"   - ìˆ˜ì§‘ëœ ì˜ìƒ: {self.stats.total_videos_collected}ê°œ")
                logger.info(f"   - ì²˜ë¦¬ëœ ì˜ìƒ: {self.stats.total_videos_processed}ê°œ")
                logger.info(f"   - íŠ¸ë Œë”© ì˜ìƒ: {self.stats.trending_videos_count}ê°œ")
                logger.info(f"   - íŒŒì¼ í¬ê¸°: {self.stats.file_size_bytes:,} bytes")
                
            else:
                logger.error("âŒ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                self.stats.error_count += 1
            
        except Exception as e:
            logger.error(f"ì¼ë³„ ìˆ˜ì§‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            self.stats.error_count += 1
            
        finally:
            await self._cleanup_collector()
            self.is_running = False
            self.stats.end_time = datetime.now().isoformat()
        
        return self.stats
    
    async def run_batch_collection(self, date_range: List[str]) -> List[CollectionStats]:
        """
        ì—¬ëŸ¬ ë‚ ì§œì— ëŒ€í•œ ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤í–‰
        
        Args:
            date_range: ìˆ˜ì§‘í•  ë‚ ì§œ ëª©ë¡ (YYYY-MM-DD í˜•ì‹)
            
        Returns:
            ê° ë‚ ì§œë³„ ìˆ˜ì§‘ í†µê³„ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ“… ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘: {len(date_range)}ê°œ ë‚ ì§œ")
        
        all_stats = []
        
        for target_date in date_range:
            try:
                logger.info(f"ğŸ“Š {target_date} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                stats = await self.run_daily_collection(target_date)
                all_stats.append(stats)
                
                # ë°°ì¹˜ ê°„ ë”œë ˆì´ (API í• ë‹¹ëŸ‰ ê´€ë¦¬)
                await asyncio.sleep(5)
                
            except Exception as e:
                logger.error(f"{target_date} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        # ë°°ì¹˜ ìˆ˜ì§‘ ìš”ì•½
        total_videos = sum(stats.total_videos_processed for stats in all_stats)
        total_trending = sum(stats.trending_videos_count for stats in all_stats)
        total_errors = sum(stats.error_count for stats in all_stats)
        
        logger.info(f"ğŸ¯ ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ:")
        logger.info(f"   - ì²˜ë¦¬ëœ ë‚ ì§œ: {len(all_stats)}/{len(date_range)}")
        logger.info(f"   - ì´ ì˜ìƒ ìˆ˜: {total_videos:,}ê°œ")
        logger.info(f"   - ì´ íŠ¸ë Œë”©: {total_trending:,}ê°œ")
        logger.info(f"   - ì´ ì˜¤ë¥˜: {total_errors}ê°œ")
        
        return all_stats
    
    def get_stats(self) -> CollectionStats:
        """ìˆ˜ì§‘ í†µê³„ ë°˜í™˜"""
        return self.stats
    
    async def _initialize_collector(self):
        """ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”"""
        logger.info("ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì¤‘...")
        
        self.data_collector = YouTubeTrainingDataCollector(
            api_keys=self.config.youtube_api_keys,
            output_dir=self.config.output_directory
        )
        await self.data_collector.__aenter__()
        
        logger.info("ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def _cleanup_collector(self):
        """ë°ì´í„° ìˆ˜ì§‘ê¸° ì •ë¦¬"""
        logger.info("ë°ì´í„° ìˆ˜ì§‘ê¸° ì •ë¦¬ ì¤‘...")
        
        if self.data_collector:
            await self.data_collector.__aexit__(None, None, None)
        
        logger.info("ë°ì´í„° ìˆ˜ì§‘ê¸° ì •ë¦¬ ì™„ë£Œ")
    
    async def _update_collection_stats(self, csv_path: str):
        """ìˆ˜ì§‘ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.stats.csv_file_path = csv_path
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            if os.path.exists(csv_path):
                self.stats.file_size_bytes = os.path.getsize(csv_path)
                
                # CSV íŒŒì¼ì—ì„œ í†µê³„ ì¶”ì¶œ
                try:
                    import csv as csv_module
                    with open(csv_path, 'r', encoding='utf-8-sig') as f:
                        reader = csv_module.DictReader(f)
                        rows = list(reader)
                        
                        self.stats.total_videos_processed = len(rows)
                        self.stats.trending_videos_count = sum(
                            1 for row in rows if row.get('is_trending_category') == '1'
                        )
                        
                except Exception as e:
                    logger.error(f"CSV í†µê³„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # API ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
            if self.data_collector:
                remaining_quota = self.data_collector.quota_manager.get_remaining_quota()
                self.stats.api_quota_used = 10000 - remaining_quota  # ê¸°ë³¸ í• ë‹¹ëŸ‰ì—ì„œ ì°¨ê°
                
        except Exception as e:
            logger.error(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
# ì„¤ì • ë¡œë“œ í•¨ìˆ˜
def load_config_from_env() -> TrainingSystemConfig:
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ"""
    youtube_api_keys = os.getenv("YOUTUBE_API_KEYS", "").split(",")
    youtube_api_keys = [key.strip() for key in youtube_api_keys if key.strip()]
    
    if not youtube_api_keys:
        raise ValueError("YOUTUBE_API_KEYS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    return TrainingSystemConfig(
        youtube_api_keys=youtube_api_keys,
        collection_schedule=os.getenv("COLLECTION_SCHEDULE", "daily"),
        batch_size=int(os.getenv("BATCH_SIZE", "100")),
        output_directory=os.getenv("OUTPUT_DIRECTORY", "results"),
        min_view_count=int(os.getenv("MIN_VIEW_COUNT", "1000")),
        enable_data_validation=os.getenv("ENABLE_DATA_VALIDATION", "true").lower() == "true"
    )


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ì„¤ì • ë¡œë“œ
        config = load_config_from_env()
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        system = YouTubeTrainingSystem(config)
        
        # ì¼ë³„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        stats = await system.run_daily_collection()
        
        if stats.csv_file_path:
            logger.info("ğŸ‰ YouTube í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ!")
            logger.info(f"ìƒì„±ëœ CSV: {stats.csv_file_path}")
        else:
            logger.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìê°€ í”„ë¡œê·¸ë¨ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())